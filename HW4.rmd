---
title: "Homework 4"
date: '2023-02-10'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.align="center")
```

## Loading relevant libraries 

```{r message=F}
library(dplyr)
library(tidyverse)
library(caret)
library(glmnet)
library(ROCR)
library(dbarts)
library(bestglm)
library(ranger)
library(rpart)
library(rpart.plot)
library(ggplot2)
```

# Question 2
## Reading the data
```{r}
housing.train = read.csv('housing_train.csv')
housing.test = read.csv('housing_test.csv')
```
## Data cleaning
```{r}
str(housing.train)
housing.train <- housing.train %>% mutate(logSP=log(Sale_Price))
```
## 2.1
### Histogram of $SalePrice$
```{r}
hist(housing.train$Sale_Price)
```

### Histogram of $log(SalePrice)$
```{r}
hist(housing.train$logSP)
```
### Scatterplot between $SalePrice$ and $Gr_Liv_Area$
```{r}
housing.train %>% ggplot(aes(Sale_Price, Gr_Liv_Area)) +
  geom_point()
``` 

### Scatterplot between $log(SalePrice)$ and $Gr_Liv_Area$
```{r}
housing.train %>% ggplot(aes(logSP, Gr_Liv_Area)) +
  geom_point()
``` 
## 2.2

```{r}
housing.train <- housing.train[,-1]
fwd.step.bic = bestglm(housing.train, 
                       family = gaussian, 
                       IC     = "BIC",
                       method = "forward")
fwd.step.bic
```
31

```{r}
fwd.step.bic$Subsets
```

```{r}
dev.plot = -2 * fwd.step.bic$Subsets$logLikelihood
bic.plot = fwd.step.bic$Subsets$BIC
plot(0:99, dev.plot, lwd=2, col='black', type='p',
     ylim = c(min(dev.plot), max(bic.plot)),
     xlab='Subset Size', ylab='Deviance', main='All subsets')
points(0:99, bic.plot, lwd=2, col='red')
legend("topright", legend=c("deviance", "BIC"), col=c("black", "red"), pch=1)
```


```{r}
fwd.step.cv = bestglm(housing.train, 
                      family = gaussian, 
                      IC     = "CV",
                      CVArgs = list(Method="HTF", K=10, REP=1),
                      method = "forward")
fwd.step.cv
```
12
```{r}
fwd.step.cv$Subsets
```

```{r}
dev.plot = -2 * fwd.step.cv$Subsets$logLikelihood
cverrs = fwd.step.cv$Subsets$CV
sdCV = fwd.step.cv$Subsets$sdCV
CVLo = cverrs - sdCV
CVHi = cverrs + sdCV
k = 0:(length(cverrs)-1)
plot(k, cverrs, xlab="Subset Size", ylab="CV Error", main='All subsets',
     ylim=c(min(CVLo),max(CVHi)), type="n")
points(k, cverrs, cex=2, col="red", pch=16)
lines(k, cverrs, col="red", lwd=2)
# plot error bars
segments(k, CVLo, k, CVHi, col="blue", lwd=2)
eps = 0.15
segments(k-eps, CVLo, k+eps, CVLo, col="blue", lwd=2)
segments(k-eps, CVHi, k+eps, CVHi, col="blue", lwd=2)

indBest = oneSDRule(fwd.step.cv$Subsets[,c("CV", "sdCV")])
abline(v=indBest-1, lty=2)
indMin = which.min(cverrs)
fmin = sdCV[indMin]
cutOff = fmin + cverrs[indMin]
abline(h=cutOff, lty=2)
indMin = which.min(cverrs)
abline(v=indMin-1, lty=2)

points(0:99, dev.plot, lwd=2, col='black')
legend("topright", legend=c("deviance", "CV"), col=c("black", "red"), pch=1)
```

## 2.3
**Lasso**: $\hat{\beta} = \text{argmin}_{\beta} \Big\{ \text{deviance} +\lambda \|\beta\|_1\Big\}$
```{r}
x = as.matrix( housing.train[,1:99] )
y = housing.train[,100]
lasso.fit = glmnet(x, y)
plot( lasso.fit, xvar = "lambda" )
plot( lasso.fit, xvar = "norm" )
```


```{r}
data.frame(lasso = as.matrix(coef(lasso.fit, s = c(5, 1, 0.5))),
           LS    = coef(lm(y ~ x)))
```

We observe that the lasso  
  
- Can shrink coefficients exactly to zero  
- Simultaneously estimates and selects coefficients  

We need to choose lambda.  

```{r}
lasso.cv = cv.glmnet(x, y)
plot(lasso.cv, sign.lambda=-1)
```


```{r}
glmnet.fit <- lasso.cv$glmnet.fit
plot(glmnet.fit, xvar = "lambda")
abline(v = log(lasso.cv$lambda.min), lty=2, col="red")
abline(v = log(lasso.cv$lambda.1se), lty=2, col="green")
legend("topright", legend=c("min", "1se"), lty=2, col=c("red", "green"))
```

Let us investigate coefficients for these values of lambda:
```{r}
coef(lasso.cv, s = c(lasso.cv$lambda.min, lasso.cv$lambda.1se))
```
## 2.4

## 2.5

```{r}
h.test <- model.matrix(~.-y,data=housing.test)
pred <- predict(lasso.cv$glmnet.fit, h.test, s=lasso.cv$lambda.min)
yhat = exp(pred)
#sampleSubmission is a dataframe with columns 'Id' and 'count'
sampleSubmission = data.frame(Id=1:length(yhat), Sale_Price=yhat)
write.csv(sampleSubmission,
          file = "sampleSubmission.csv",
          row.names = FALSE,
          quote = FALSE)
```

```{r}
#hh
```

